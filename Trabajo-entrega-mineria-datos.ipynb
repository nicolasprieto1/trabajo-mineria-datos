{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de recomendacion para un Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estudiantes:\n",
    "\n",
    "- Victoria Alvarez\n",
    "- Karen Velasquez\n",
    "- Ana Uran\n",
    "- Nicolas Prieto\n",
    "- Pablo A. Saldarriaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde486061c7d46eda9f797b2a6eca985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1600268116866_0003</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Imports iniciales\n",
    "import os\n",
    "from time import time\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import StringIndexer, StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit,CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5529a9d56d4a828a9793996c07d4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/74/69/18b96b520519818e00b04dd08d7cbc5e764f1465f5a280cf96173f34c54e/pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib64/python3.7/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.1.2 python-dateutil-2.8.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%configure -f \n",
    "#{\"driverMemory\": \"20000M\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de la información (NO SE EJECUTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso inicial consiste en leer la información alojada en diferentes buckets de S3\n",
    "\n",
    "Inicialmente se da lectura a los metadatos de los productos con el fin de que estos sean la base para aplicación de modelos cold star, esta metadata fue descargada del enlace http://jmcauley.ucsd.edu/data/amazon/ y posteriormente almacenada en un bucket propio de S3.\n",
    "\n",
    "Adicionalmente, leemos los datos del amazon customer review data set que se encuentran en un bucket público de amazon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Lectura de la metadata de los productos\n",
    "df_metadata = spark.read.csv(\"s3://info-proyecto-mineria-datos/metadata/products_*.csv\", header = True, multiLine=True, quote='\"',escape='\"',sep=',').drop_duplicates(subset=['asin'])\n",
    "df_metadata = df_metadata.select('customer_id','product_id','star_rating')\n",
    "df_metadata.persist()\n",
    "#Contar filas de productos\n",
    "print(f'Cantidad de productos en la metadata: {df_metadata.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd8c93e1275468b97634fb69cc7d150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[customer_id: string, product_id: string, star_rating: string]"
     ]
    }
   ],
   "source": [
    "### Cargamos la informacion de todos los reviews almacenados en S3\n",
    "df_reviews = spark.read.csv(\"s3://amazon-reviews-pds/tsv/amazon_reviews_us_*.tsv.gz\", sep= '\\t', header = True)\n",
    "df_reviews = df_reviews.select('customer_id','product_id','star_rating')\n",
    "df_reviews.persist()\n",
    "### Imprimimos el esquema del conjunto de datos y mostramos las primeras 5 filas\n",
    "df_reviews.printSchema()\n",
    "df_reviews.show(5)\n",
    "\n",
    "### Numero de registros que tiene el conjunto de datos\n",
    "print(f'La cantidad de reviews que tenemos es: {df_reviews.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Al conjunto de datos de los reviews le agregamos la metadata de los productos\n",
    "reviews = df_reviews.alias('reviews')\n",
    "products = df_metadata.alias('products')\n",
    "\n",
    "all_data = reviews.join(products, reviews.product_id == products.asin,how='left')\n",
    "all_data.select('product_id','asin','star_rating','price','title').show(5)\n",
    "all_data.persist()\n",
    "\n",
    "### Verificar que no cambie la cantidad de reviews despues del join\n",
    "print(f'La cantidad de reviews despues del join es: {all_data.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminamos los registros que no tengan informacion de asin, precio y titulo\n",
    "df_clean = df_reviews.na.drop(subset = ['asin'])\n",
    "df_clean.select('product_id','asin','star_rating','price','title').show()\n",
    "df_clean.persist()\n",
    "\n",
    "print(f'La cantidad de reviews despues de la eliminacion es: {df_clean.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtenemos la cantidad de productos diferentes que se tiene en el conjunto de datos de los reviewa\n",
    "df_clean.agg(countDistinct(col(\"product_id\")).alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2.persist()\n",
    "df_clean2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bf4c5fa3ca4fba9809e8bbd50ba27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90983354"
     ]
    }
   ],
   "source": [
    "# Debido a que existen productos con muy pocos reviews y esto afecta el desempeño de los modelos implementados \n",
    "# se filtran la base inicialmente parap productos con más de 150 reviews y se juega con este parámetro para conocer la capacidad\n",
    "# máxima del cluster y de esta forma escalar los modelos.\n",
    "\n",
    "df_reviews.createOrReplaceTempView(\"df_clean\")\n",
    "df_clean2 = spark.sql(\"\"\"with category as (\n",
    "                                    SELECT \n",
    "                                        product_id, \n",
    "                                        count(*) as n_reviews \n",
    "                                        FROM \n",
    "                                        df_clean  group by product_id), \n",
    "                                        category_def as (select * from category where n_reviews >= 25) select t1.* \n",
    "                                        from \n",
    "                                        df_clean as t1 inner join category_def as t2 on t1.product_id = t2.product_id \n",
    "                                        where t1.star_rating in ('1','2','3','4','5') \"\"\")\n",
    "df_clean2.persist()\n",
    "df_clean2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357e023c332344d2a50e364a133d2e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[customer_id: string, product_id: string, star_rating: string]"
     ]
    }
   ],
   "source": [
    "# Adicionalmente se incluyen solo reseñas de clientes que hallan hecho más de 5 reviews, con el fin de mejorar el performance \n",
    "# teniendo en cuenta que en el desarrollo del proyecto se tratará el problema del cold star.\n",
    "df_clean2.createOrReplaceTempView(\"df_clean2\")\n",
    "df_final = spark.sql(\"\"\"with category as (\n",
    "                                    SELECT \n",
    "                                        customer_id, \n",
    "                                        count(*) as n_customers \n",
    "                                        FROM \n",
    "                                        df_clean2  group by customer_id), \n",
    "                                        category_def as (select * from category where n_customers >= 5) select t1.* \n",
    "                                        from \n",
    "                                        df_clean2 as t1 inner join category_def as t2 on t1.customer_id = t2.customer_id \n",
    "                                        where t1.star_rating in ('1','2','3','4','5') \"\"\")\n",
    "\n",
    "df_final.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4802f6b78d41f0a2d3eae326ceb825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58547703"
     ]
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a55d20fd54962a600f28aceea608f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generamos un index para cada código de producto\n",
    "indexer_product_id = StringIndexer(inputCol=\"product_id\", outputCol=\"item\")\n",
    "df = indexer_product_id.fit(df_final).transform(df_final)\n",
    "\n",
    "# Generamos un indice para cada transacción con el fin de luego poderla identificar\n",
    "ratings_df = df.select(\"*\").withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9e3d822b78497384e385ea590087e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Garantizamos que estén incluidos los nuevos campos\n",
    "ratings_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfbd982685d4885be936321b8f6eeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58547703"
     ]
    }
   ],
   "source": [
    "#Cantidad de reviews analizados\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c06b157333d4a38a9433d59015c7b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Guardamos en un bucket S3 reviews asociados a productos que tienen más de 150 de estos\n",
    "#ratings_df.write.parquet(\"s3a://mineria-info/muestra_genera14M.parquet\")#>50\n",
    "\n",
    "ratings_df.write.parquet(\"s3a://mineria-datos-20202/muestra_genera14M.parquet\")#>50\n",
    "\n",
    "#ratings_df.write.parquet(\"s3a://mineria-info/muestra_genera31M.parquet\")#>100\n",
    "#ratings_df.write.parquet(\"s3a://mineria-info/muestra_genera24M.parquet\")#>150 prods ESTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de muestra guardada en S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos la información de la muestra base con la que desarrollaremos el modelamiento incial, que es el resultado del procedimiento anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44edcd1daad7491793f4c1248c975415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de reviews a considerar es: 14919839"
     ]
    }
   ],
   "source": [
    "#df = spark.read.parquet(\"s3a://mineria-info/muestra_general.parquet\")\n",
    "df = spark.read.parquet(\"s3a://mineria-datos-20202/muestra_genera14M.parquet\") ### 14 24 44 49 62\n",
    "print(f'La cantidad de reviews a considerar es: {df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se extrae la cantidad de productos, usuarios y reviews analizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0d46489abe46e99cd263272cdce56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+--------------+\n",
      "|cuenta_productos|cuenta_usuarios|cuenta_reviews|\n",
      "+----------------+---------------+--------------+\n",
      "|          115434|         765213|      14919839|\n",
      "+----------------+---------------+--------------+"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"df_base\")\n",
    "\n",
    "\n",
    "info_cuentas = spark.sql(\"\"\" SELECT \n",
    "                                COUNT(DISTINCT product_id) as cuenta_productos, \n",
    "                                COUNT(DISTINCT customer_id) as cuenta_usuarios, \n",
    "                                COUNT(customer_id) as cuenta_reviews \n",
    "                                FROM \n",
    "                                df_base\"\"\")\n",
    "\n",
    "info_cuentas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestreo para training, validation y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la muestra , se realiza un muestreo estratificado por producto donde se calcula la proporción de cada ítem dentro de la muestra total de 14.9 millones, con el fin de mantener dicha proporción en los grupos de entrenamiento, validación y testeo.\n",
    "\n",
    "\n",
    "\n",
    "Esta muestra de 14.9 millones de reviews fue divida en un 60% - 20% - 20% para datos de entrenamiento, validación y testeo\n",
    "\n",
    "**Procedimiento:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce104387a44b08947bab03029704e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14919839"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los las variables relevantes\n",
    "\n",
    "ratings_df = spark.sql(\"\"\" SELECT \n",
    "                                cast(t1.star_rating as int) as star_rating_integer, \n",
    "                                cast(t1.customer_id as int) as customer_id_integer, \n",
    "                                t1.product_id, \n",
    "                                t1.item , \n",
    "                                t1.id \n",
    "                                FROM \n",
    "                                df_base t1\"\"\")\n",
    "ratings_df.persist()\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa064b2a15b4e799cd3a619d90ffef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Selección de muestra: Debido a que es necesario garantizar que exista participación de todos los productos en el set de datos\n",
    "\n",
    "NH2 = ratings_df.groupBy('product_id').count() #Poblacion por cada pruduct category\n",
    "n = 0.6\n",
    "\n",
    "list_of_lat2 = NH2.rdd.map(lambda r: (r.product_id,n)).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebcd658e52f43879eb444e5614ca6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[star_rating_integer: int, customer_id_integer: int, product_id: string, item: double, id: bigint]"
     ]
    }
   ],
   "source": [
    "ratings_df_training = ratings_df.sampleBy(\"product_id\", fractions=list_of_lat2,seed=10)\n",
    "ratings_df_training.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de muestras para validación y test ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1b22fbaaf5458e824fc5e144330677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[star_rating_integer: int, customer_id_integer: int, product_id: string, item: double, id: bigint]"
     ]
    }
   ],
   "source": [
    "ratings_df_training.createOrReplaceTempView(\"df_training\")\n",
    "ratings_df.createOrReplaceTempView(\"df_general\")\n",
    "\n",
    "#Proceso para excluir lo que ya se encuentra en el set de training\n",
    "ratings_df_aux = spark.sql(\"\"\" SELECT \n",
    "                                    t1.*  \n",
    "                                    FROM \n",
    "                                    df_general as t1 left join df_training as t2 on t1.id = t2.id \n",
    "                                    WHERE \n",
    "                                    t1.id is null or t2.id is null \"\"\")\n",
    "ratings_df_aux.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e58fc41ddb4594853ca5c3ad4270e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[star_rating_integer: int, customer_id_integer: int, product_id: string, item: double, id: bigint]"
     ]
    }
   ],
   "source": [
    "### Obtención de conjunto de validación y test\n",
    "NH3 = ratings_df_aux.groupBy('product_id').count()\n",
    "n = 0.5\n",
    "\n",
    "list_of_lat3 = NH3.rdd.map(lambda r: (r.product_id,n)).collectAsMap()\n",
    "\n",
    "### Test\n",
    "ratings_df_test = ratings_df_aux.sampleBy(\"product_id\", fractions=list_of_lat3,seed=10)\n",
    "ratings_df_test.persist()\n",
    "\n",
    "\n",
    "### Validation\n",
    "ratings_df_test.createOrReplaceTempView(\"df_test\")\n",
    "ratings_df_aux.createOrReplaceTempView(\"df_aux\")\n",
    "\n",
    "ratings_df_val = spark.sql(\"\"\"SELECT \n",
    "                                    t1.*  \n",
    "                                    FROM \n",
    "                                    df_aux as t1 left join df_test as t2 on t1.id = t2.id \n",
    "                                    WHERE \n",
    "                                    t1.id is null or t2.id is null \"\"\")\n",
    "ratings_df_val.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa la división de cada uno de las muestras, siempre garantizando que exista la participación de todos los productos (items) en cada grupo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aece960b4888414583ca68b848c5f970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en training: 8952274\n",
      "Cantidad de registros en validation: 2983493\n",
      "Cantidad de registros en test: 2984072"
     ]
    }
   ],
   "source": [
    "#cantidad de registros en los conjuntos de datos, la particion se hizo 60-20-20\n",
    "print(f'Cantidad de registros en training: {ratings_df_training.count()}')\n",
    "print(f'Cantidad de registros en validation: {ratings_df_val.count()}')\n",
    "print(f'Cantidad de registros en test: {ratings_df_test.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Implementación de modelos con información histórica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de tener la información requerida para el desarrollo de los modelos, se agregan las variables de sesgo al set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd3bb03c7054a2ca77393909c6f936e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_df_training.createOrReplaceTempView(\"data_reviews\")\n",
    "\n",
    "query = \"\"\" with data_summary as (\n",
    "                            SELECT\n",
    "                                avg(star_rating_integer) as promedio_global\n",
    "                                FROM data_reviews\n",
    "                            ),\n",
    "                        cliente as(\n",
    "                            SELECT\n",
    "                                customer_id_integer,\n",
    "                                avg(star_rating_integer) as promedio_usuario\n",
    "                                FROM data_reviews\n",
    "                                GROUP BY customer_id_integer\n",
    "                        ),\n",
    "                        producto as (\n",
    "                            SELECT\n",
    "                                product_id,\n",
    "                                avg(star_rating_integer) as promedio_producto\n",
    "                                FROM data_reviews\n",
    "                                GROUP BY product_id\n",
    "                        ),\n",
    "                        summary_promg_cli as(\n",
    "                            SELECT v.*,\n",
    "                                data_summary.promedio_global as mu\n",
    "                                FROM\n",
    "                                (SELECT data_reviews.*,\n",
    "                                cliente.promedio_usuario as promedio_usuario\n",
    "                                FROM data_reviews\n",
    "                                LEFT JOIN cliente ON data_reviews.customer_id_integer=cliente.customer_id_integer) v\n",
    "                                CROSS JOIN data_summary)\n",
    "                            SELECT *,\n",
    "                                cast(star_rating_integer as int) as star_rating_int, \n",
    "                                cast(customer_id_integer as int) as customer_id_int,\n",
    "                                promedio_producto-mu as bx,\n",
    "                                promedio_usuario-mu as bi,\n",
    "                                star_rating_integer - mu - (promedio_producto-mu) -(promedio_usuario-mu) as rating_normalizado\n",
    "                                FROM (\n",
    "                                SELECT summary_promg_cli.*,\n",
    "                                    producto.promedio_producto as promedio_producto\n",
    "                                    FROM\n",
    "                                    summary_promg_cli\n",
    "                                    LEFT JOIN producto ON summary_promg_cli.product_id=producto.product_id)\"\"\"\n",
    "\n",
    "\n",
    "training_norm = spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f295f90b786b4fdb8ad54456762a2c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[customer_id_integer: int, item: double, star_rating_integer: int, bx: double, bi: double, mu: double]"
     ]
    }
   ],
   "source": [
    "training_norm.createOrReplaceTempView(\"train\")\n",
    "ratings_df_val.createOrReplaceTempView(\"val\")\n",
    "#test.createOrReplaceTempView(\"test\")\n",
    "\n",
    "query = \"\"\" with tabla_CLIENTES as(\n",
    "                            SELECT customer_id_integer,\n",
    "                                    max(bi) as bi\n",
    "                                    FROM\n",
    "                                    train\n",
    "                                    GROUP BY customer_id_integer\n",
    "                                    ),\n",
    "                tabla_ITEMS as(\n",
    "                                SELECT\n",
    "                                    item,\n",
    "                                    max(bx) as bx\n",
    "                                    FROM\n",
    "                                    train\n",
    "                                    GROUP BY item),\n",
    "                tabla_bi as (\n",
    "                SELECT \n",
    "                    val.customer_id_integer,\n",
    "                    val.star_rating_integer,\n",
    "                    val.item,\n",
    "                    tabla_CLIENTES.bi\n",
    "                    FROM\n",
    "                    tabla_CLIENTES RIGHT JOIN val ON \n",
    "                    val.customer_id_integer=tabla_CLIENTES.customer_id_integer ),\n",
    "\n",
    "                    data_summary as (\n",
    "                                SELECT\n",
    "                                    MAX(mu) as mu\n",
    "                                    FROM train\n",
    "                                )\n",
    "                SELECT *\n",
    "                    from (\n",
    "                    select\n",
    "                        tabla_bi.customer_id_integer,\n",
    "                        tabla_bi.item,\n",
    "                        tabla_bi.star_rating_integer,\n",
    "                        tabla_ITEMS.bx,\n",
    "                        tabla_bi.bi\n",
    "                        FROM\n",
    "                        tabla_bi LEFT JOIN tabla_ITEMS ON tabla_bi.item=tabla_ITEMS.item) CROSS JOIN data_summary \"\"\"\n",
    "\n",
    "val = spark.sql(query)\n",
    "val = val.fillna(0)\n",
    "val.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c66405266864e3c97e8789d9125987c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[customer_id_integer: int, item: double, star_rating_integer: int, bx: double, bi: double, mu: double]"
     ]
    }
   ],
   "source": [
    "training_norm.createOrReplaceTempView(\"train\")\n",
    "ratings_df_test.createOrReplaceTempView(\"test\")\n",
    "\n",
    "query = \"\"\" with tabla_CLIENTES as(\n",
    "                            SELECT customer_id_integer,\n",
    "                                    max(bi) as bi\n",
    "                                    FROM\n",
    "                                    train\n",
    "                                    GROUP BY customer_id_integer\n",
    "                                    ),\n",
    "                tabla_ITEMS as(\n",
    "                                SELECT\n",
    "                                    item,\n",
    "                                    max(bx) as bx\n",
    "                                    FROM\n",
    "                                    train\n",
    "                                    GROUP BY item),\n",
    "                tabla_bi as (\n",
    "                SELECT \n",
    "                    test.customer_id_integer,\n",
    "                    test.star_rating_integer,\n",
    "                    test.item,\n",
    "                    tabla_CLIENTES.bi\n",
    "                    FROM\n",
    "                    tabla_CLIENTES RIGHT JOIN test ON \n",
    "                    test.customer_id_integer=tabla_CLIENTES.customer_id_integer ),\n",
    "\n",
    "                    data_summary as (\n",
    "                                SELECT\n",
    "                                    MAX(mu) as mu\n",
    "                                    FROM train\n",
    "                                )\n",
    "                SELECT *\n",
    "                    from (\n",
    "                    select\n",
    "                        tabla_bi.customer_id_integer,\n",
    "                        tabla_bi.item,\n",
    "                        tabla_bi.star_rating_integer,\n",
    "                        tabla_ITEMS.bx,\n",
    "                        tabla_bi.bi\n",
    "                        FROM\n",
    "                        tabla_bi LEFT JOIN tabla_ITEMS ON tabla_bi.item=tabla_ITEMS.item) CROSS JOIN data_summary \"\"\"\n",
    "\n",
    "test = spark.sql(query)\n",
    "test = test.fillna(0)\n",
    "test.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92ebc9b8f57424abc6b9501acbb7f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[rating_normalizado: double, customer_id_integer: int, star_rating_integer: int, item: double]"
     ]
    }
   ],
   "source": [
    "training = training_norm.select('rating_normalizado','customer_id_integer','star_rating_integer','item')\n",
    "training.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa de modelamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo baseline consiste en obtener la calificación promedio para predecir la siguiente calificación. A partir de allí calculamos el error cuadrático medio, Los modelos baseline consisten en extraer la calificación promedio para estimar la reseña que van a dar los clientes a los productos que aún no compran. En este caso, se ejecutaron cuatro modelos baseline empleando la mediana, media global, la media por producto y por usuario.esta es la referencia para definir si los siguientes modelos presentan mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8857e22d92f642f9bf115d4b7304a3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana en training es: 5.0\n",
      "+------------------+\n",
      "|              RMSE|\n",
      "+------------------+\n",
      "|1.3090958166826092|\n",
      "+------------------+\n",
      "\n",
      "Tiempo: 172.58927488327026"
     ]
    }
   ],
   "source": [
    "### Baseline con la Mediana\n",
    "t_ini = time()\n",
    "\n",
    "training.createOrReplaceTempView(\"training_df\")\n",
    "median = spark.sql(\"select percentile_approx(star_rating_integer, 0.5) as median from training_df\")\n",
    "median = float(median.toPandas()['median'][0])\n",
    "\n",
    "print(f'La mediana en training es: {median}')\n",
    "\n",
    "se_rdd = val.rdd.map(lambda x: (x['star_rating_integer']-median)**2)\n",
    "row = Row(\"valor\")\n",
    "se_df = se_rdd.map(row).toDF()\n",
    "se_df.createOrReplaceTempView('se_df_median')\n",
    "baseline_median = spark.sql('SELECT SQRT(AVG(valor)) as RMSE  FROM se_df_median')\n",
    "baseline_median.show()\n",
    "\n",
    "print(f'Tiempo: {time()-t_ini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85128cbefd8a450a86da2d10b9c6d620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio en trainig es: 4.313211704646216\n",
      "+-----------------+\n",
      "|             RMSE|\n",
      "+-----------------+\n",
      "|1.114904805061795|\n",
      "+-----------------+\n",
      "\n",
      "Tiempo: 28.577411890029907"
     ]
    }
   ],
   "source": [
    "### Baseline con el promedio\n",
    "t_ini = time()\n",
    "\n",
    "mean = float(training.describe().toPandas()['star_rating_integer'][1]) # mean\n",
    "\n",
    "print(f'El promedio en trainig es: {mean}')\n",
    "\n",
    "se_rdd = val.rdd.map(lambda x: (x['star_rating_integer']-mean)**2)\n",
    "row = Row(\"valor\")\n",
    "se_df = se_rdd.map(row).toDF()\n",
    "se_df.createOrReplaceTempView('se_df')\n",
    "baseline = spark.sql('SELECT SQRT(AVG(valor)) as RMSE  FROM se_df')\n",
    "baseline.show()\n",
    "\n",
    "print(f'Tiempo: {time()-t_ini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d631747edf4040bc6e5efb11a1dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             RMSE|\n",
      "+-----------------+\n",
      "|1.055840559903122|\n",
      "+-----------------+\n",
      "\n",
      "Tiempo: 29.988484621047974"
     ]
    }
   ],
   "source": [
    "### Baseline promedio por producto\n",
    "t_ini = time()\n",
    "training.createOrReplaceTempView(\"training_df\")\n",
    "val.createOrReplaceTempView(\"validation_df\")\n",
    "mean_prod = spark.sql(\"\"\"with tabla_prods as(\n",
    "                        select \n",
    "                            item, \n",
    "                            AVG(star_rating_integer) as prom_prod \n",
    "                            FROM \n",
    "                            training_df\n",
    "                            GROUP BY item),\n",
    "                        table_aux as(\n",
    "                        SELECT \n",
    "                            validation_df.*,\n",
    "                            tabla_prods.prom_prod,\n",
    "                            POWER(validation_df.star_rating_integer-tabla_prods.prom_prod,2) as SE\n",
    "                            FROM\n",
    "                            validation_df LEFT JOIN tabla_prods ON validation_df.item=tabla_prods.item\n",
    "                            )\n",
    "                            SELECT SQRT(AVG(SE)) as RMSE\n",
    "                            FROM\n",
    "                            table_aux\n",
    "                            \"\"\")\n",
    "                        \n",
    "mean_prod.show()\n",
    "print(f'Tiempo: {time()-t_ini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bf37061edc45568b02152f4626a14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              RMSE|\n",
      "+------------------+\n",
      "|1.0676053136258488|\n",
      "+------------------+\n",
      "\n",
      "Tiempo: 32.09034276008606"
     ]
    }
   ],
   "source": [
    "### Modelo baseline promedio por usuario\n",
    "\n",
    "t_ini = time()\n",
    "training.createOrReplaceTempView(\"training_df\")\n",
    "val.createOrReplaceTempView(\"validation_df\")\n",
    "mean_cli = spark.sql(\"\"\"with tabla_customers as(\n",
    "                        select \n",
    "                            customer_id_integer, \n",
    "                            AVG(star_rating_integer) as prom_prod \n",
    "                            FROM \n",
    "                            training_df\n",
    "                            GROUP BY customer_id_integer)\n",
    "                        SELECT \n",
    "                            validation_df.*,\n",
    "                            tabla_customers.prom_prod\n",
    "                            FROM\n",
    "                            validation_df LEFT JOIN tabla_customers ON validation_df.customer_id_integer=tabla_customers.customer_id_integer\n",
    "                            \n",
    "                            \"\"\")\n",
    "### para aquellos que no se les asigno un promedio por usuario\n",
    "### ponemos el promedio global\n",
    "mean_cli = mean_cli.fillna(mean)\n",
    "\n",
    "mean_cli.createOrReplaceTempView(\"tabla_clientes_f\")\n",
    "mean_cli_final = spark.sql(\"\"\"with tabla_errores as(\n",
    "                                SELECT\n",
    "                                    POWER(tabla_clientes_f.star_rating_integer-tabla_clientes_f.prom_prod,2) as SE\n",
    "                                    FROM\n",
    "                                    tabla_clientes_f )\n",
    "                                    SELECT SQRT(AVG(SE)) as RMSE\n",
    "                                        FROM\n",
    "                                        tabla_errores\n",
    "                                    \"\"\")\n",
    "\n",
    "mean_cli_final.show()\n",
    "print(f'Tiempo: {time()-t_ini}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Factores latentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se emplea modelos de factores latentes utilizando el algoritmo ALS, el modelo fue entrenado con el conjunto de training previamente mencionado y validado con el conjunto validation, los inputs recibidos por el modelo son el user id correspondiente a la identificación del usuario que califico el producto,  el  star rating que corresponde a la puntuación generada por el usuario y  el item correspondiente al producto calificado por el usuario, siendo estas las variables iniciales para el modelo; como se menciono previamente se realizo la aplicación de diferentes combinaciones entre hiper parámetros generando un total de 9 modelos, a continuación se listan los hiper parámetros (iteraciones, factores latentes y regularización) y resultados de cada modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo inicial**\n",
    "- **rank** = 10 por defecto\n",
    "- **maxIter** = 10 por defecto \n",
    "- **regParam** = 0.1 por defectp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3f560e3fc44483b8802a319ef9cba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 62.3497815132 seconds."
     ]
    }
   ],
   "source": [
    "### Entrenamiento del modelo\n",
    "start_time = time()\n",
    "\n",
    "als = ALS(userCol=\"customer_id_integer\", itemCol=\"item\", ratingCol=\"star_rating_integer\",\n",
    "          coldStartStrategy=\"drop\",nonnegative=True) #rank=10, maxIter=10, regParam=0.1\n",
    "model = als.fit(ratings_df_training)\n",
    "\n",
    "elapsed_time = time() - start_time\n",
    "print(\"Elapsed time: %.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2a0e2c917e44d886976c9b81c7e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.2609236011967255\n",
      "Elapsed time: 223.0072054863 seconds."
     ]
    }
   ],
   "source": [
    "### Metrica del modelo en validación\n",
    "start_time = time()\n",
    "predictions = model.transform(ratings_df_val)\n",
    "predictions_corr = predictions.withColumn(\"preds_corr\",\n",
    "                               when(col(\"prediction\") < 1 , 1)\n",
    "                              .when(col(\"prediction\") > 5 , 5)\n",
    "                              .otherwise(col(\"prediction\")))\n",
    "predictions_corr.persist()\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"star_rating_integer\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions_corr)\n",
    "\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "print(\"Elapsed time: %.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de realizar las combinaciones previamente mencionadas se entranan modelos con diferentes hiperparámetros\n",
    "\n",
    "- **rank** = la cantidad de factores latentes en el modelo (5, 10 y 15 como valores seleccionados)\n",
    "- **maxIter** = el número máximo de iteraciones (valor predeterminado 10)\n",
    "- **regParam** = el parámetro de regularización (0.01, 0.1 y 0.50 como valores seleccionados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5415ef5cfbb842db80c0299d0df85cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def als_pipeline(df_train,df_val,s,rank, maxiter):\n",
    "    \n",
    "    als = ALS(maxIter=maxiter, \n",
    "              rank =rank , \n",
    "              regParam=s, \n",
    "              userCol=\"customer_id_integer\", \n",
    "              itemCol=\"item\", \n",
    "              ratingCol=\"star_rating_integer\",\n",
    "              coldStartStrategy=\"drop\")\n",
    "    \n",
    "    model = als.fit(df_train)\n",
    "    predictions = model.transform(df_val)\n",
    "    predictions_corr = predictions.withColumn(\"preds_corr\",\n",
    "                               when(col(\"prediction\") < 1 , 1)\n",
    "                              .when(col(\"prediction\") > 5 , 5)\n",
    "                              .otherwise(col(\"prediction\")))\n",
    "    \n",
    "    predictions_corr.persist()\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"star_rating_integer\",predictionCol=\"preds_corr\")\n",
    "    testset_rmse = evaluator.evaluate(predictions_corr)\n",
    "    \n",
    "    return testset_rmse,s,rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3587b5a9ddf44a4b3ab10052ccc7bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " variables - 0.01- 5\n",
      " variables - 0.01- 10\n",
      " variables - 0.01- 15\n",
      " variables - 0.1- 5\n",
      " variables - 0.1- 10\n",
      " variables - 0.1- 15\n",
      " variables - 0.5- 5\n",
      " variables - 0.5- 10\n",
      " variables - 0.5- 15\n",
      "+------------------+--------+------------------+----+\n",
      "|              rmse|regParam|            tiempo|rank|\n",
      "+------------------+--------+------------------+----+\n",
      "|1.2848505714790919|    0.01|120.71894645690918|   5|\n",
      "|1.6607101670554205|    0.01|128.82892322540283|  10|\n",
      "|2.1466029049154316|    0.01|137.08186554908752|  15|\n",
      "|  1.14548601464932|     0.1|120.69456386566162|   5|\n",
      "|1.1661973080989725|     0.1|129.01196765899658|  10|\n",
      "| 1.159792668536722|     0.1|140.32774305343628|  15|\n",
      "|1.1225435993849013|     0.5| 128.7129738330841|   5|\n",
      "|1.1213726094604428|     0.5| 131.4477515220642|  10|\n",
      "| 1.121463316816976|     0.5|  142.866845369339|  15|\n",
      "+------------------+--------+------------------+----+"
     ]
    }
   ],
   "source": [
    "downsamples = [0.01, 0.1, 0.5]\n",
    "rango = [5, 10, 15] \n",
    "rmses = [] \n",
    "for s in downsamples:\n",
    "    for d in rango:\n",
    "        start_time = time()\n",
    "        print(f\" variables - {s}- {d}\")\n",
    "        test_rmse,s,rank = als_pipeline(training,val,s,d, 10)\n",
    "        elapsed_time = time() - start_time\n",
    "        rmses.append([test_rmse,s,elapsed_time,rank])\n",
    "        \n",
    "df_metrica2 = spark.createDataFrame(rmses,['rmse','regParam','tiempo','rank'])\n",
    "df_metrica2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en la tabla previa, el mejor modelo basado en la métrica RMSE es el que tiene como hiper parámetros 10 iteraciones, 10 factores latentes y 0.5 como parámetro de regularización, permitiéndonos obtener el menor RMSE con un valor  1.121373; de acuerdo a estos resultados, se elige como modelo para ser comparado con el resto de modelos incluidos dentro de la sección, buscando elegir el modelo con mejor desempeño que permita realizar las recomendaciones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de factores latentes con sesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se incluyen sesgos al modelo de factores latentes. Se consideraron sesgos globales (media global), a nivel de usuario (media por usuario menos media global) y a nivel de producto (media por producto menos media global). Estos fueron adicionados a la predicción del modelo de filtros colaborativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ee066faa4f4923b1b05a9234455f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def als_bias_pipeline(df_train,df_test,s,rank, maxiter):\n",
    "    \n",
    "    ### realizamos una instancia del modelo\n",
    "    als = ALS(maxIter=maxiter, \n",
    "              rank =rank , \n",
    "              regParam=s, \n",
    "              userCol=\"customer_id_integer\", \n",
    "              itemCol=\"item\", \n",
    "              ratingCol=\"rating_normalizado\",\n",
    "              coldStartStrategy=\"drop\")\n",
    "    \n",
    "    ### Entrenamos el modelo\n",
    "    model = als.fit(df_train)\n",
    "    \n",
    "    ### Realizamos la prediccion del modelo en conjutno de validacion\n",
    "    ### e incorporamos el sesgo a la prediccion\n",
    "    predictions = model.transform(df_test)\n",
    "    predictions= predictions.withColumn(\"Preds_bias\", predictions.prediction + \n",
    "                                                      predictions.mu + \n",
    "                                                      predictions.bx +\n",
    "                                                      predictions.bi)\n",
    "    \n",
    "    predictions.persist()\n",
    "    predictions_corr = predictions.withColumn(\"preds_corr\",\n",
    "                                   when(col(\"Preds_bias\") < 1 , 1)\n",
    "                                  .when(col(\"Preds_bias\") > 5 , 5)\n",
    "                                  .otherwise(col(\"Preds_bias\")))\n",
    "    ### Obtenemos la metrica en el conjunto de validacion\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"star_rating_integer\",predictionCol=\"Preds_bias\")\n",
    "    testset_rmse = evaluator.evaluate(predictions_corr)\n",
    "    \n",
    "    return testset_rmse, s, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b433a4d8f60f49c8bcf3d6b3d6fce40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4641029019407945"
     ]
    }
   ],
   "source": [
    "### Realizamos una ejecucion del modelo con bias\n",
    "testset_rmse_B,s_B,rank_B = als_bias_pipeline(training,val,0.01,10,10)\n",
    "print(testset_rmse_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f625ad66cd7747eebcc4855ddeecff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 3457\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " variables - 0.01- 5\n",
      " variables - 0.01- 10\n",
      " variables - 0.01- 15\n",
      " variables - 0.1- 5\n",
      " variables - 0.1- 10\n",
      " variables - 0.1- 15\n",
      " variables - 0.5- 5\n",
      " variables - 0.5- 10\n",
      " variables - 0.5- 15\n",
      "+------------------+--------+------------------+----+\n",
      "|              rmse|regParam|            tiempo|rank|\n",
      "+------------------+--------+------------------+----+\n",
      "|1.4937858560486668|    0.01|109.81022238731384|   5|\n",
      "|1.4641029019407945|    0.01|120.35951352119446|  10|\n",
      "|1.3523364347797808|    0.01| 125.5230360031128|  15|\n",
      "| 1.136435419937925|     0.1|110.04429459571838|   5|\n",
      "|1.1230690346479222|     0.1|118.56872224807739|  10|\n",
      "|1.1014438485647313|     0.1|127.20243740081787|  15|\n",
      "|1.0301370926307816|     0.5|113.56155252456665|   5|\n",
      "|1.0301242393107255|     0.5|119.25893378257751|  10|\n",
      "|1.0301196359631826|     0.5|125.81444311141968|  15|\n",
      "+------------------+--------+------------------+----+"
     ]
    }
   ],
   "source": [
    "downsamples = [0.01, 0.1, 0.5]# list of percentages to downsample training set\n",
    "rango = [5, 10, 15] \n",
    "rmses = [] \n",
    "for s in downsamples:\n",
    "    for d in rango:\n",
    "        start_time = time()\n",
    "        print(f\" variables - {s}- {d}\")\n",
    "        test_rmse,s,rank = als_bias_pipeline(training,val,s,d, 10)\n",
    "        elapsed_time = time() - start_time\n",
    "        rmses.append([test_rmse,s,elapsed_time,rank])\n",
    "        \n",
    "df_metricaB = spark.createDataFrame(rmses,['rmse','regParam','tiempo','rank'])\n",
    "df_metricaB.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en la tabla previa, el mejor modelo basado en la métrica RMSE es el que tiene como hiper parámetros 10 iteraciones, 15 factores latentes y 0.5 como parámetro de regularización, permitiéndonos obtener el menor RMSE con un valor  1.030120; de acuerdo a estos resultados, se elige como modelo para ser comparado con el resto de modelos incluidos dentro de la sección, buscando elegir el modelo con mejor desempeño que permita realizar las recomendaciones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base en los resultados anteriores, se tiene que el mejor modelo es el implementado con FACTORES LATENTES CON SESGOS con un RMSE en el conjunto de validacion de 1.030120, por lo cual este será elegido como el modelo final de modelos con información histórica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion del modelo en conjunto de prueba\n",
    "\n",
    "Basado en el mejor resultado anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b06e16f1b7f4704aa8b946cb0ffc7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.019881018369282\n",
      "Tiempo ejecucion: 231.606201171875"
     ]
    }
   ],
   "source": [
    "time_ini = time()\n",
    "als = ALS(maxIter=10, \n",
    "          rank =15 , \n",
    "          regParam=0.5, \n",
    "          userCol=\"customer_id_integer\", \n",
    "          itemCol=\"item\", \n",
    "          ratingCol=\"rating_normalizado\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "\n",
    "### Entrenamos el modelo\n",
    "model = als.fit(training)\n",
    "\n",
    "### Realizamos la prediccion del modelo en conjutno de validacion\n",
    "### e incorporamos el sesgo a la prediccion\n",
    "predictions = model.transform(test)\n",
    "predictions= predictions.withColumn(\"Preds_bias\", predictions.prediction + \n",
    "                                                  predictions.mu + \n",
    "                                                  predictions.bx +\n",
    "                                                  predictions.bi)\n",
    "\n",
    "predictions.persist()\n",
    "predictions_corr = predictions.withColumn(\"preds_corr\",\n",
    "                               when(col(\"Preds_bias\") < 1 , 1)\n",
    "                              .when(col(\"Preds_bias\") > 5 , 5)\n",
    "                              .otherwise(col(\"Preds_bias\")))\n",
    "\n",
    "### Obtenemos la metrica en el conjunto de validacion\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"star_rating_integer\",predictionCol=\"preds_corr\")\n",
    "testset_rmse = evaluator.evaluate(predictions_corr)\n",
    "print(testset_rmse)\n",
    "print(f'Tiempo ejecucion: {time()-time_ini}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar el mejor modelo en el conjunto de test obtenemos que el RMSE en es de 1.019881 obteniendo una mejor métrica e indicando que estos resultados son consistentes e incluso mejores con respecto a los obtenidos en validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de aplicacion - Recomendacion de productos a usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos ver el top número 1 para cada usuario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59e8f5147224de4a8eda2b094b08f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|customer_id_integer|     recommendations|\n",
      "+-------------------+--------------------+\n",
      "|              10206|[[115069, 0.01608...|\n",
      "|              12566|[[101600, 0.02665...|\n",
      "|              13406|[[101600, 0.00660...|\n",
      "|              15062|[[114125, 0.00672...|\n",
      "|              23123|[[5883, 0.0037734...|\n",
      "|              23619|[[113655, 0.00304...|\n",
      "|              24252|[[115292, 4.60627...|\n",
      "|              31264|[[111962, 0.00516...|\n",
      "|              37004|[[114184, 0.00800...|\n",
      "|              37827|[[102789, 0.00289...|\n",
      "|              43548|[[114125, 0.02941...|\n",
      "|              44185|[[113237, 0.00129...|\n",
      "|              46318|[[108465, 0.00669...|\n",
      "|              47067|[[108805, 0.00248...|\n",
      "|              48077|[[111560, 0.05213...|\n",
      "|              51528|[[104777, 0.06587...|\n",
      "|              54110|[[114485, 0.08473...|\n",
      "|              60683|[[113329, 0.00162...|\n",
      "|              62320|[[100366, 5.73255...|\n",
      "|              67630|[[105027, 0.00586...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "userRecs = model.recommendForAllUsers(1)\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos cold start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo usa un MinHashLSH primero para hallar los articulos mas similares a un cierto producto basandose en el título de éste. Este producto podria ser un \"producto nuevo\" sin ningun problema, lo cual lo hace un modelo apto para el cold start (simplemente se necesita tener la metadata de este articulo). \n",
    "Usando LSH, se hallan los \"n\" productos mas similares para este articulo.\n",
    "Luego de este paso, en una segunda etapa se usan las variables de precio, categoría y marca del artículo y de sus \"n\" artículos más similares para computar un score de afinidad, y con este score podremos determinar cuales son los \"m\" artículos más afines al producto de interés de entre los \"n\" artículos similares hallados en la etapa 1.\n",
    "Estos \"m\" artículos que salen del segundo paso serían los artículos que se recomiendan junto con este artículo. Así, a las personas que hayan comprado alguno de los \"m\" productos, se les debe recomendar también el producto de interés.\n",
    "\n",
    "Para validar el rendimiento de este modelo, se extraen algunos artículos del conjunto de datos general y se dejan aparte en un conjunto de validación. Para predecir los ratings de estos artículos, se toma el promedio de los \"m\" artículos más afines según este procedimiento. Éste sería el rating predicho para este artículo (sin importar el usuario) y con este rating se calcularía la métrica (RMSE) del modelo (comparando los ratings predichos contra los reales) para ver su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e44f1be5e9a49d095da88e4623ae0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1599766849228_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-80-10.ec2.internal:20888/proxy/application_1599766849228_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-80-45.ec2.internal:8042/node/containerlogs/container_1599766849228_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.414817810058594e-05s"
     ]
    }
   ],
   "source": [
    "#### El proceso descrito anteriormente usariamos 3 hiperparametros principales, los cuales son\n",
    "import time\n",
    "time1 = time.time()\n",
    "## \"n\", numero maximo de vecinos que se obtendrian con el algoritmo de LSH\n",
    "n = 15\n",
    "\n",
    "## \"m\", numero maximo de productos mas afines que se sacarian calculando un score para los n vecinos obtenidos con LSH\n",
    "m = 5\n",
    "\n",
    "## \"numhasht\", numero de tablas de Hash a usar en el objeto MinHashLSH\n",
    "numhasht = 5\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8479245283a94da98ed87e5b8447eebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      asin|avg_rating|\n",
      "+----------+----------+\n",
      "|0001839233|       4.0|\n",
      "|0002199009|       4.5|\n",
      "|0002239221|      4.25|\n",
      "|0002261952|       4.0|\n",
      "|0002553465|       5.0|\n",
      "|0002554623|       5.0|\n",
      "|0006931863|       5.0|\n",
      "|0007135653|       5.0|\n",
      "|0007180691|       4.0|\n",
      "|0007216521|       5.0|\n",
      "|0007230060|       5.0|\n",
      "|0007242980|       4.0|\n",
      "|0007338155|       4.5|\n",
      "|0007391382|       5.0|\n",
      "|0007416865|       4.0|\n",
      "|0007439237|      4.25|\n",
      "|0007514794|       5.0|\n",
      "|0007823819|       5.0|\n",
      "|0013073915|       4.5|\n",
      "|0020183402|       4.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "### Lectura de parquet con ratings por producto\n",
    "ratings_producto = spark.read.parquet(\"s3://info-proyecto-mineria-datos/ratings_producto.parquet\")\n",
    "ratings_producto.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258e05ce127e41c693423d35186e2c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Lectura del dataframe de metadata\n",
    "### Limitar filas para que corra en tiempo prudente\n",
    "#limite = 3000000\n",
    "df_metadata = spark.read.csv(\"s3://info-proyecto-mineria-datos/metadata/products_*.csv\", header = True, multiLine=True, quote='\"',escape='\"',sep=',').drop_duplicates(subset=['asin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308480985e4647c9ae308740cdaabd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704294"
     ]
    }
   ],
   "source": [
    "### El dataset que se usara es el df_metadata. Descartaremos todos los productos que tengan campos nulos\n",
    "df_metadata_full = df_metadata.na.drop()\n",
    "df_metadata_full = df_metadata_full.filter(df_metadata_full.price.contains('$'))\n",
    "\n",
    "### Dejar solo los que existan los ratings (solo estos cuentan como productos de nuestro dataset)\n",
    "df_metadata_full = ratings_producto.select('asin').join(df_metadata_full, 'asin', how='inner')\n",
    "\n",
    "df_metadata_full.persist()\n",
    "df_metadata_full.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffa2c53e5b44765bb148786acc38d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      ": string (nullable = true)\n",
      "\n",
      "Productos de entrenamiento: 3704250\n",
      "Productos de validacion: 44"
     ]
    }
   ],
   "source": [
    "### Dividir los datos en entrenamiento y validacion\n",
    "df_metadata_cl=df_metadata_full.sample(False, 0.999987, seed=1) ## se ajusta para que sean aprox 40 productos en validacion\n",
    "df_metadata_cl.printSchema()\n",
    "df_metadata_cl.persist()\n",
    "print('Productos de entrenamiento: '+str(df_metadata_cl.count()))\n",
    "\n",
    "df_metadata_val=df_metadata_full.join(df_metadata_cl,['asin'], \"left_anti\")\n",
    "df_metadata_val.persist()\n",
    "\n",
    "print('Productos de validacion: '+str(df_metadata_val.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d12436faf8542f99a24afa9c3fe1bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|\n",
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|B004GW5UM6|  $0.91|Maracas Rattle Ha...|                Jive|['Toys & Games', ...|['', '<b> Materia...|\n",
      "|B005J4MYYM|  $6.92|Black Zipper Earr...|     Forum Novelties|['Clothing, Shoes...|['BLACK ZIPPER EA...|\n",
      "|B00TOLW7N4|$166.99|OEM Evinrude E-Te...|Johnson Evinrude OMC|['Automotive', 'M...|['Brand new, genu...|\n",
      "|B00BW7MV98|$129.99|Beautiful Life Ur...| Beautiful Life Urns|['Home & Kitchen'...|['', 'With an ele...|\n",
      "|B00J5YV7PY| $12.99|T-Power (6.6ft Lo...|             T POWER|['Electronics', '...|['T-Power Made wi...|\n",
      "|0578150492|  $6.10|Kathleen and Oona...|Visit Amazon's Wi...|['Books', 'Parent...|[\"This book is a ...|\n",
      "|B0079V2P9M| $22.98|.925 Sterling Sil...|          Queenberry|['Clothing, Shoes...|['It fits major b...|\n",
      "|1575053861|  $5.97|Octopuses (Nature...|Visit Amazon's Ro...|['Books', \"Childr...|[\"Grade 4-6-A sli...|\n",
      "|0688076629|  $9.75|Royal Sisters: Qu...|Visit Amazon's An...|['Books', 'Histor...|['The lives of th...|\n",
      "|0763647357| $18.99|Salem Brownstone:...|Visit Amazon's Jo...|['Books', 'Teen &...|[\"Grade 8 Up A te...|\n",
      "|B006F8Z3N0|$215.48|FMF Fatty Pipe Ni...|                 FMF|['Automotive', 'M...|[\"The Fatty Gold ...|\n",
      "|0972249508| $11.76|21st Century Sell...|Visit Amazon's Jo...|['Books', 'Busine...|['Is selling in t...|\n",
      "|1405791454| $28.38|Cases That Change...|       Ian McDougall|['Books', 'Law', ...|            ['', '']|\n",
      "|B00H8XZZXY| $10.99|Wellington RDBNBK...|          Wellington|['Sports & Outdoo...|['RDBNBK3815 Refl...|\n",
      "|0399115218|  $6.92|     The Viking saga|Visit Amazon's Pe...|['Books', 'Histor...|['Book is used an...|\n",
      "|\n",
      "|B0002FTCS4| $12.29|Wiha 36271 Tamper...|                Wiha|['Tools & Home Im...|['Wiha 36271 tamp...|\n",
      "|B00007AKDL| $19.07|Kodak ESP 6150 Al...|               Kodak|['Office Products...|['Your business i...|\n",
      "|B00EZ8H12S|$339.99|Simadre 5000d 110...|             Simadre|['Tools & Home Im...|['SIMADRE CT5000D...|\n",
      "|B0009YWDKM| $52.97|Jurassic Park - D...|       Jurassic Park|['Toys & Games', ...|['1993 Jurassic P...|\n",
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_metadata_val.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4af3c0991c4edf8b044e7d332d187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               words|            features|\n",
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|0001714422|  $5.82|'C' Is for Clown ...|Visit Amazon's St...|                  []|[\"C IS FOR CLOWN ...|[c, is, for, clow...|(262144,[3,12,105...|\n",
      "|0002168383| $32.25|The Beatles: For ...|            P. Cowan|                  []|['Original 1st ed...|[the, beatles, fo...|(262144,[0,3,2013...|\n",
      "|0002216973|$123.94|     Red Adam's Lady|Visit Amazon's Gr...|['Books', 'Litera...|[\"<div><div><B>Gr...|[red, adam, s, lady]|(262144,[5,44,925...|\n",
      "|    [running, blind]|(262144,[953,3287...|\n",
      "+----------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "19.77097988128662s"
     ]
    }
   ],
   "source": [
    "### Tokenizar los textos y crear conteos de las palabras (shingling)\n",
    "time1 = time.time()\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"title\", outputCol=\"words\", pattern='\\w+', gaps=False)\n",
    "characterDataFrame = regexTokenizer.transform(df_metadata_cl)\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", binary=True)\n",
    "count_model = cv.fit(characterDataFrame)\n",
    "\n",
    "### Quitar nulos\n",
    "resulta = count_model.transform(characterDataFrame)\n",
    "resu = resulta.withColumn(\"label\", resulta[\"features\"].cast(StringType()))\n",
    "resu = resu.filter(~resu.label.contains('[]'))\n",
    "result = resu.drop('label')\n",
    "\n",
    "result.show(4,truncate=True)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4d16c1974648edb1fa295ce62dcd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40893054008483887s"
     ]
    }
   ],
   "source": [
    "## Ahora, usar el objeto de MinHashLSH, para entrenar el modelo de MinHashLSH con los productos conocidos de la base de datos\n",
    "time1 = time.time()\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=numhasht, seed=1234)\n",
    "lsh_model = mh.fit(result)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo de las metrica de RMSE para el modelo de cold start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46ec05af45d48dda36d785b6166b7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.70896029472351s"
     ]
    }
   ],
   "source": [
    "## Hallemos los n vecinos mas similares para cada uno de los productos de test\n",
    "time1 = time.time()\n",
    "### Productos nuevos (conjunto de validacion)\n",
    "sentences = df_metadata_val.select(\"title\").rdd.flatMap(lambda x: x).collect()\n",
    "price_val = df_metadata_val.select(\"price\").rdd.flatMap(lambda x: x).collect()\n",
    "brand_val = df_metadata_val.select(\"brand\").rdd.flatMap(lambda x: x).collect()\n",
    "category_val = df_metadata_val.select(\"category\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "\n",
    "\n",
    "### Vecinos similares a cada producto\n",
    "similares_parte1=[]\n",
    "\n",
    "### Hallar \"n\" mas similares para cada producto\n",
    "for sentence in sentences:\n",
    "    sentenceDataFrame = spark.createDataFrame([\n",
    "    (0, sentence)\n",
    "    ], [\"id\", \"title\"])\n",
    "    char2 = regexTokenizer.transform(sentenceDataFrame)\n",
    "    outp2 = count_model.transform(char2)\n",
    "    outputDataFrame = lsh_model.transform(outp2)\n",
    "    key = outputDataFrame.head().features\n",
    "    similars = lsh_model.approxNearestNeighbors(result, key, n)\n",
    "    similars.persist()\n",
    "    similares_parte1.append(similars)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1abb82a93844a208f3f71fe3c6135db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Definimos aqui un par de funciones auxiliares\n",
    "\n",
    "### Funcion para obtener el precio como numero\n",
    "def obtiene_precio(precio):\n",
    "    precio1 = precio.replace('$','')\n",
    "    precio2 = precio1.replace(',','')\n",
    "    precio3 = precio2.split(' ')\n",
    "    precio4 = 0\n",
    "    count=0\n",
    "    for i in precio3:\n",
    "        if len(i.strip())>1:\n",
    "            count = count+1\n",
    "            precio4 = precio4+float(i)\n",
    "    return precio4/count\n",
    "\n",
    "\n",
    "### Funcion para calcular la similaridad de Jaccard (para las listas)\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d85fff741c4f60a7f88a4609cd543d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B006HV5TD4', 'B006I3CTX4', 'B006IBYR2W', 'B002YEP528', 'B001GI12IY']\n",
      "['B00ZSOWJAM', 'B00Q6F7AN8', 'B002HO9QBG', 'B00HBR8A84', 'B00005Y7NC']\n",
      "['B00R56YRLU', 'B00MAO9UO6', 'B008BVZM30', 'B00K08OQKW', 'B004ZJBL64']\n",
      "['B00BW7RKKS', 'B00BW7LYC8', 'B00BW7LWHA', 'B00BW7M6TI', 'B00BW7RX64']\n",
      "['B00CJ26LAU', 'B00JMTVQ3K', 'B00J5YUYVW', 'B00J5YUX18', 'B00DIL1GNS']\n",
      "['1907056017', '0552527564', '1481817248', '0064431460', '0425266354']\n",
      "['B00K4T70R8', 'B003XYHF30', 'B004WHU7BY', 'B005J2F5UE', 'B005N38V1Y']\n",
      "['1575054825', '1575050781', '1575058707', '1575052938', '1575055775']\n",
      "['1441120726', '0762446455', '0718123123', 'B004VLYHN0', '0750238860']\n",
      "['B000Z31ZJ2', '1479194670', '0060141557', '0967917360', '0984915109']\n",
      "['B001RZ2IBQ', 'B006F8Y76E', 'B0074ENRVY', 'B001RZ6KT2', 'B000GUWSPO']\n",
      "['1891024388', '0824826280', '1559362006', '0140172483', '0989302105']\n",
      "['B000H6SY28', '0310238188', 'B000AXWHHQ', 'B001TH37O4', '1492149659']\n",
      "['B00H8XZZFC', 'B00H8Y01SM', 'B00H8Y0146', 'B001HBUDE4', 'B002TA0D4C']\n",
      "['1494399083', '0375873236', '0812533313', '0312283903', '1453722661']\n",
      "['0310332680', 'B000H5TUFO', '1625490267', '0615307779', '1477829296']\n",
      "['B000T9QZ7O', 'B000T9W780', 'B000T9UH82', 'B0002FT8W4', 'B001ID4V26']\n",
      "['B0016KISAC', 'B001VEJ23A', 'B000F2KRGK', 'B000Y4IMFM', 'B0038AN3YE']\n",
      "['B00F0UB9BY', 'B000ITVRJG', 'B005OGWSA0', 'B001OHRN94', 'B002EA22YQ']\n",
      "['B00005KAL4', 'B0009YYVES', 'B0009YUK84', 'B000HD0BWW', 'B000EGZFV4']\n",
      "['1602643504', '0877289077', '0877288976', '143447710X', '1552670066']\n",
      "['160684220X', '1617060518', '1458210936', '0980105803', '1440443629']\n",
      "['B007WLWQC0', 'B001PZF7PM', 'B00HYKQ6XY', 'B00488G4X2', 'B004DNZU8M']\n",
      "['B00BD4DPYU', 'B00QAW0OEY', 'B005CEC9K8', 'B00Q43K9R6', 'B005I7BUWW']\n",
      "['B00EFGH2CE', 'B00EZXS2QM', 'B00FIAOP9Y', 'B00EZXPHEW', 'B00F21FFJS']\n",
      "['B00BVUA0NK', 'B009WDZG4G', 'B00BVU7V9G', 'B007TU1VUM', 'B007TU1YFY']\n",
      "['1569871124', 'B0016N46R8', '0862837243', '0862837278', '1568581637']\n",
      "['B0068PLIA2', 'B000X61W9O', 'B00023G7JI', 'B006MHSFO8', 'B00CJFDIXA']\n",
      "['B008VQMW9M', 'B008VQN60G', 'B008VQMS46', 'B008VMR4WG', 'B008VQQN10']\n",
      "['098856436X', '0979646707', '1560373210', '0898866502', '1441455957']\n",
      "['B006O0UOJC', 'B005NAQG0K', 'B003H295VI', 'B00KYOGMLS', 'B0071GWLVW']\n",
      "['B00CPYZ3CO', 'B00C67JPGU', 'B002P9YE7Y', 'B003J2RO14', 'B00513XAXA']\n",
      "['B008M4RFM2', 'B00AGROEHC', 'B008M4RE3M', 'B008M4RHX4', 'B008M4RIHO']\n",
      "['1118692756', '0553114719', '1592802923', '0070580995', '1592803075']\n",
      "['B007VQ9QHE', 'B00AQEVBU8', 'B009GHYL9E', 'B00LG4HRNC', 'B009GHYMRU']\n",
      "['B001G7EJ5S', 'B001G7NTO0', 'B001G79HBO', 'B001G7TL8S', 'B001G7IQHK']\n",
      "['B000A7Q1VU', 'B001FBSMF8', 'B0021BSOHM', 'B0016CP1RS', 'B000KA1798']\n",
      "['B008Y5OWQG', 'B00000AE4C', 'B000003G3P', 'B000002NFR', 'B000005LB2']\n",
      "['B00002N6GQ', 'B000NPF1BU', 'B007ZIZTI8', 'B003EW1IQG', 'B00L0EVCNY']\n",
      "['B000FZZ0CI', 'B000FZ1KF4', 'B000G13JR4', 'B000G0ATGE', 'B000G16GZ6']\n",
      "['157174164X', '0847831639', '0988392828', '0972306935', '1626970696']\n",
      "['B00RZV1NCG', 'B0041FQZMW', 'B00SM00B7C', 'B001EJLPQO', 'B00UNRI9XA']\n",
      "['129191806X', '0985579021', '0615922201', '1481430696', '0718006291']\n",
      "['6302824435', '6302658519', '6303356583', '6304480261', '1572524413']\n",
      "1399.457034111023s"
     ]
    }
   ],
   "source": [
    "### Ahora, hallar los m mas afines a los n mas similares de cada producto\n",
    "time1 = time.time()\n",
    "count = 0\n",
    "mas_afines_son = []\n",
    "for cruzados_sim_1 in similares_parte1:\n",
    "    ### Extraigamos de la metadata todas las filas relacionados a cada uno de los segun LSH\n",
    "    #cruzados_sim_1 = vecino_n.select(\"asin\").join(df_metadata_cl, \"asin\", how='left')\n",
    "    \n",
    "\n",
    "    \n",
    "    ### Listas de asin, precios, marcas y categorias de los n mas similares\n",
    "    cruzare = cruzados_sim_1.rdd.flatMap(lambda x: x).collect()\n",
    "    price_son=[]\n",
    "    asin_son=[]\n",
    "    brand_son=[]\n",
    "    category_son=[]\n",
    "    for i in range(len(cruzare)):\n",
    "        est = cruzare[i]\n",
    "        if i%10==0:\n",
    "            asin_son.append(est)\n",
    "        if i%10==1:\n",
    "            price_son.append(est)\n",
    "        if i%10==3:\n",
    "            brand_son.append(est)\n",
    "        if i%10==4:\n",
    "            category_son.append(est)\n",
    "\n",
    "    \n",
    "    ### Listas de asin, precios, marcas y categorias del producto \"nuevo\"\n",
    "    price_es = price_val[count]\n",
    "    brand_es = brand_val[count]\n",
    "    category_es = category_val[count]\n",
    "    \n",
    "    \n",
    "    ### Preprocesar los precios: transformacion logaritmica y hallar distancia maxima al precio promedio\n",
    "    import math\n",
    "    precios_son = []\n",
    "    precio_es = math.log(obtiene_precio(price_es), 10)\n",
    "    max_distanc = 0\n",
    "    for p in price_son:\n",
    "        estep = math.log(obtiene_precio(p), 10)\n",
    "        precios_son.append(estep)\n",
    "        dista = abs(precio_es-estep)\n",
    "        if dista > max_distanc:\n",
    "            max_distanc = dista\n",
    "            \n",
    "    ## Por si todos eran iguales\n",
    "    if max_distanc==0:\n",
    "        max_distanc=1\n",
    "            \n",
    "            \n",
    "    ### Ahora, vamos a calcular entonces los score para cada uno de los n vecinos\n",
    "    scores = []\n",
    "    for i in range(len(precios_son)):\n",
    "        score = 0\n",
    "\n",
    "        ### Score de marca\n",
    "        if brand_son[i] == brand_es and brand_es and brand_son[i]:\n",
    "            score = score+1\n",
    "        ### Score de categoria (cuantas coinciden, similaridad jaccard)\n",
    "        if category_es and category_son[i]:\n",
    "            simi = jaccard_similarity(category_es, eval(category_son[i]))\n",
    "            score = score + simi\n",
    "\n",
    "        ### Score de precio\n",
    "        score = score + (1 - (abs(precio_es-precios_son[i]))/max_distanc)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        \n",
    "    ### Recomendar entonces los m con mayor score\n",
    "    import numpy as np\n",
    "    index_recomendados = np.argsort(scores)[::-1][:m]\n",
    "    asin_rec = list(np.array(asin_son)[index_recomendados])\n",
    "    print(asin_rec)\n",
    "    count = count+1\n",
    "    mas_afines_son.append(asin_rec)\n",
    "    #title_rec = list(np.array(title_son)[index_recomendados])\n",
    "    #print(title_rec)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los productos mas afines a cada uno de los productos del conjunto de validación. Ahora, calculamos el rating promedio de todos los productos más afines a cada producto, y este sería el rating predicho para cada uno de nuestros productos. Con estos ratings predichos y ya mirando los datos reales, calculamos la métrica RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba17fc2b9a2a4d1898c565841e174a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B004GW5UM6', 'B005J4MYYM', 'B00TOLW7N4', 'B00BW7MV98', 'B00J5YV7PY', '0578150492', 'B0079V2P9M', '1575053861', '0688076629', '0763647357', 'B006F8Z3N0', '0972249508', '1405791454', 'B00H8XZZXY', '0399115218', '0615657869', 'B0002FTCS4', 'B00007AKDL', 'B00EZ8H12S', 'B0009YWDKM', '8188018066', '0595518036', 'B002IZ9JKW', 'B006YG58H4', 'B00F21EVN4', 'B00CODHUMM', '1569871108', 'B000PSAI90', 'B00CU6GCGS', '0937207039', 'B006O0Y84Y', 'B007YH0IJU', 'B008M4RDH4', '0984638709', 'B005GI8H4M', 'B001G7OU48', 'B003HLM2QO', '0914390260', 'B000BQKTUE', 'B000G0CVOC', '0340768339', 'B00YHV2GVO', '0007455925', '6304560540']\n",
      "1.0046167373657227s"
     ]
    }
   ],
   "source": [
    "### Los product id de los productos del conjunto de validacion son \n",
    "time1 = time.time()\n",
    "asin_val = df_metadata_val.select(\"asin\").rdd.flatMap(lambda x: x).collect()\n",
    "print(asin_val)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394411d8eb5941a9b54d1de3261284c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Esta funcion recibe la lista de los mas similares a cada producto, y retorna el rating promedio de esos productos\n",
    "### mas similares. Este rating seria el rating predicho para este producto\n",
    "import pyspark.sql.functions as F\n",
    "def prediccion(lista):\n",
    "    predicho=[]\n",
    "    for i in range(len(lista)):\n",
    "        registro=ratings_producto.filter(F.col(\"asin\").isin(lista[i]))\n",
    "        t = registro.groupBy().agg(F.avg(\"avg_rating\").alias('cnt')).collect()\n",
    "        predicho.append(t[0].cnt)\n",
    "    return(predicho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2fa31d1c78475dbe008b2366011970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-53:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 2396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.46, 2.6, 4.6, 4.86590909090909, 4.404999999999999, 4.794047619047619, 3.4850000000000003, 4.55, 4.31904761904762, 4.603361344537815, 5.0, 3.736666666666667, 4.251075268817205, 3.866666666666667, 3.8059758771929824, 4.757333333333333, 5.0, 2.8485134371478233, 3.9468376068376068, 4.15, 4.35, 3.9253869969040247, 5.0, 4.377142857142857, 4.2, 3.9814285714285718, 4.8, 4.597105943152455, 4.0, 4.703488372093023, 4.225957918050942, 4.2, 3.5200000000000005, 3.6625, 4.6, 3.8666666666666663, 4.141733120680489, 4.5, 3.7142857142857144, 4.3681196434520135, 4.809523809523809, 4.303207810320781, 4.7043478260869565, 3.883333333333333]\n",
      "34.138073682785034s"
     ]
    }
   ],
   "source": [
    "### Los ratings predichos para cada uno de los productos del set de validacion serian\n",
    "time1 = time.time()\n",
    "ratings_pred_val = prediccion(mas_afines_son)\n",
    "print(ratings_pred_val)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c5df4d62fa4e4582bb38a4c195d065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.5, 3.8, 4.5, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.857142857142857, 2.573529411764706, 5.0, 4.0, 4.5625, 4.666666666666667, 5.0, 5.0, 5.0, 3.5, 5.0, 5.0, 5.0, 4.8, 4.756756756756757, 5.0, 3.0, 4.333333333333333, 4.75, 5.0, 3.702127659574468, 4.5, 5.0, 2.75, 4.4, 5.0, 5.0, 4.619047619047619]\n",
      "33.740506649017334s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-67:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Mientras que los ratings reales de esos productos son\n",
    "time1 = time.time()\n",
    "ratings_reales=[]\n",
    "for id_es in asin_val:\n",
    "    registro_es = ratings_producto.filter(ratings_producto.asin.contains(id_es))\n",
    "    rating_es = registro_es.groupBy().agg(F.avg(\"avg_rating\").alias('cnt')).collect()\n",
    "    ratings_reales.append(rating_es[0].cnt)\n",
    "print(ratings_reales)\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a714cb33ed417689e77d83bc16aefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RMSE del modelo diseñado para cold start en validacion es: 0.7136821332912172\n",
      "0.00047016143798828125s"
     ]
    }
   ],
   "source": [
    "### Calculamos entonces el MSE entre los ratings predichos y los reales\n",
    "time1 = time.time()\n",
    "re_es = np.array(ratings_reales)\n",
    "pr_es = np.array(ratings_pred_val)\n",
    "rmse = np.sqrt(np.mean((re_es - pr_es)**2))\n",
    "print('El RMSE del modelo diseñado para cold start en validacion es: ' + str(rmse))\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ae400a2c2e4771b37649a293fe11ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RMSE de un modelo baseline (promedio general) en validacion es: 0.7190592527767478\n",
      "3.587758779525757s"
     ]
    }
   ],
   "source": [
    "### Si hubieramos usado la media global de los ratings de producto, el MSE hubiera sido\n",
    "### El dataset que se usara es el df_metadata. Descartaremos todos los productos que tengan campos nulos\n",
    "time1 = time.time()\n",
    "\n",
    "### Dejar solo los que existan los ratings (solo estos cuentan como productos de nuestro dataset)\n",
    "df_aux_prom = ratings_producto.join(df_metadata_cl, 'asin', how='inner')\n",
    "\n",
    "promedio_prod = df_aux_prom.groupBy().agg(F.avg(\"avg_rating\").alias('averag')).collect()\n",
    "\n",
    "\n",
    "re_es = np.array(ratings_reales)\n",
    "prbase_es = np.array([promedio_prod[0].averag]*len(ratings_reales))\n",
    "rmse = np.sqrt(np.mean((re_es - prbase_es)**2))\n",
    "print('El RMSE de un modelo baseline (promedio general) en validacion es: ' + str(rmse))\n",
    "\n",
    "print(str(time.time()-time1)+'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor calculado sería la raíz del error cuadrático medio para los productos que quedaron en el conjunto de validación, los cuales no hacían parte del dataset de productos ya conocidos por el MinHashLSH y por ende esto representaría adecuadamente como sería el uso en producción de este modelo de cold start (recibiría productos que no conoce). \n",
    "\n",
    "(Nota: Tener en cuenta que aquí el RMSE se calcula comparando el rating predicho para cada producto con el rating promedio real de cada producto. Se hace con los promedios de los ratings de los productos en vez de con las reviews originales para facilitar los cálculos y los procesamientos. Sin embargo, se podría en una fase más avanzada o en una puesta en producción del modelo considerar incluir otros factores como por ejemplo los sesgos (bias) de los usuarios para mejorar aún más las recomendaciones de este modelo.)\n",
    "\n",
    "Cómo se puede ver, a pesar de no tener un RMSE tan bueno como los modelos de factorización de matrices con factores latentes de la sección anterior que además incluían Bias, el RMSE obtenido por este modelo es de igual forma decente, por lo que es una buena alternativa para cuando se tenga que dar recomendaciones en el ámbito del problema de cold start (cuando hay productos nuevos, el modelo de la sección anterior no estaría diseñado para sugerir recomendaciones para esos productos nuevos, pero este modelo si podría usarse en esos casos). \n",
    "\n",
    "De igual forma, se observa que el modelo solo logra superar levemente al baseline de la media, lo que indica que hay amplias oportunidades de mejora y de trabajo futuro, sin embargo, tener en cuenta que el modelo usado involucra MinHashLSH y lo que busca es encontrar los vecinos más similares de cada producto, en vez de intentar optimizar una métrica (como el rmse) como si lo hacen muchos otros modelos de ML, por lo que no consideramos como un problema el hecho de que el RMSE encontrado aquí no sea muy bueno. Lo que es realmente más importante en este modelo es que los productos que encuentra sí sean muy similares a los productos del conjunto de validación (que harían el papel de productos nuevos). \n",
    "\n",
    "Esta capacidad de encontrar productos muy similares al producto nuevo para poder dar buenas recomendaciones en el caso de cold start se aprecia mucho mejor en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo para un producto nuevo cualquiera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos ahora el ejemplo para un producto nuevo cualquiera, para ver como funcionaría el modelo en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e061a80ec7e546269c0ebcc8d51612ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": string, words: array<string>, features: vector, hashes: array<vector>, distCol: double]"
     ]
    }
   ],
   "source": [
    "\n",
    "### Metadata de producto nuevo\n",
    "sentence='Girls pink tutu dress'\n",
    "price_es = '$19.99'\n",
    "brand_es = 'Hello Kitty'\n",
    "category_es = ['Dance', 'Sports & Outdoors', 'Clothing', 'Clothing, Shoes & Jewelry']\n",
    "\n",
    "\n",
    "### Hallar \"n\" mas similares para cada producto\n",
    "sentenceDataFrame = spark.createDataFrame([\n",
    "(0, sentence)\n",
    "], [\"id\", \"title\"])\n",
    "char2 = regexTokenizer.transform(sentenceDataFrame)\n",
    "outp2 = count_model.transform(char2)\n",
    "outputDataFrame = lsh_model.transform(outp2)\n",
    "key = outputDataFrame.head().features\n",
    "similares_parte1 = (lsh_model.approxNearestNeighbors(result, key, n))\n",
    "similares_parte1.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0f19ed7ac943adb138a387a575b65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------------------------------+----------------------+-----------------------------------+\n",
      "|      asin|          price|                              title|                 brand|                           category|\n",
      "+----------+---------------+-----------------------------------+----------------------+-----------------------------------+\n",
      "|B00M66FYZC|$22.00 - $65.00|Little Girls Birthday Cupcake Pi...|        Ella Blu Store|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B00G3JICN4|         $29.89|SOPO Hello Kitty Toddler Dress B...|                  SoPo|['Clothing, Shoes & Jewelry', 'B...|\n",
      "|B00QGMY3EU|$18.60 - $34.99|Clementine Little Girls' Girls T...|    Clementine Apparel|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B006PFJMGW|         $29.99|Rare Editions Little Girls' Tutu...|         Rare Editions|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|0000031909|          $6.94|Mystiqueshapes Girls Ballet Tutu...|        Mystiqueshapes|['Sports & Outdoors', 'Sports & ...|\n",
      "|0000031852|          $7.50|   Girls Ballet Tutu Zebra Hot Pink|                  Tutu|['Sports & Outdoors', 'Sports & ...|\n",
      "|B00SH78APA|$10.13 - $22.99| Hello Kitty Baby Girls' Tutu Dress|           Hello Kitty|['Clothing, Shoes & Jewelry', 'N...|\n",
      "|B0053WLHEI|         $19.95|Rare Editions Little Girls' Tutu...|         Rare Editions|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B00DDVYABS|         $14.99|The Queens Treasures Pink Tutu D...|  The Queens Treasures|['Toys & Games', 'Dolls & Access...|\n",
      "|B00P835VGC|$25.99 - $28.00|Bloch Girls' Toddler Tiffany Dre...|                 Bloch|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B00VQEW9WG|         $13.99|Coral Pink Rosettes PETS Tutu Pa...|             Kirei Sui|['Pet Supplies', 'Dogs', 'Appare...|\n",
      "|B003JL8LNK|         $34.99|Rare Editions Little Girls' Tutu...|         Rare Editions|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B0072D0GPC|          $9.99|Pink Angel Little Girls' Stripe ...|            Pink Angel|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B00DNKCG38|         $29.99|Classykidzshop DS1708 - Pink/Fus...|        Classykidzshop|['Clothing, Shoes & Jewelry', 'G...|\n",
      "|B00OM1VVTM|         $12.50|Pink Snowflake Tutu Dress-18&quo...|American Fashion World|['Toys & Games', 'Dolls & Access...|\n",
      "+----------+---------------+-----------------------------------+----------------------+-----------------------------------+"
     ]
    }
   ],
   "source": [
    "### Extraigamos de la metadata todas las filas relacionadas a los similares segun LSH\n",
    "cruzados_sim_1 = similares_parte1.select('asin', 'price', 'title', 'brand', 'category')\n",
    "cruzados_sim_1.show(truncate=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e6745225b742cfaf5327ad1f94e205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Listas de asin, precios, marcas y categorias de similares\n",
    "asin_son = cruzados_sim_1.select(\"asin\").rdd.flatMap(lambda x: x).collect()\n",
    "price_son = cruzados_sim_1.select(\"price\").rdd.flatMap(lambda x: x).collect()\n",
    "brand_son = cruzados_sim_1.select(\"brand\").rdd.flatMap(lambda x: x).collect()\n",
    "category_son = cruzados_sim_1.select(\"category\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "\n",
    "### Preprocesar los precios: transformacion logaritmica y hallar distancia maxima al precio promedio\n",
    "import math\n",
    "precios_son = []\n",
    "precio_es = math.log(obtiene_precio(price_es), 10)\n",
    "max_distanc = 0\n",
    "for p in price_son:\n",
    "    estep = math.log(obtiene_precio(p), 10)\n",
    "    precios_son.append(estep)\n",
    "    dista = abs(precio_es-estep)\n",
    "    if dista > max_distanc:\n",
    "        max_distanc = dista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759af6af4980415b945abab140997728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44686547727749876, 0.7864036194257403, 1.0087743644900575, 0.7983980114364735, 0.375, 0.4483519406675256, 2.0442880176822786, 1.1799248576206023, 0.7279132507452283, 1.001745205571626, 0.6626532628156876, 0.6526433215161971, 0.526153524763874, 0.7415798296182917, 0.556205667456434]"
     ]
    }
   ],
   "source": [
    "### Ahora, vamos a calcular entonces los score para cada uno de los n vecinos\n",
    "scores = []\n",
    "for i in range(len(precios_son)):\n",
    "    score = 0\n",
    "    #print(price_son[i])\n",
    "    #print(category_son[i]) \n",
    "    ### Score de marca\n",
    "    if brand_son[i] == brand_es and brand_es and brand_son[i]:\n",
    "        score = score+1.0\n",
    "    #print(score)\n",
    "\n",
    "    ### Score de categoria (cuantas coinciden, similaridad jaccard)\n",
    "    if category_es and category_son[i]:\n",
    "        simi = jaccard_similarity(category_es, eval(category_son[i]))\n",
    "    #    print(simi)\n",
    "        score = score + simi\n",
    "    #print(score)\n",
    "    \n",
    "    ### Score de precio\n",
    "    score = score + (1 - (abs(precio_es-precios_son[i]))/max_distanc)\n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "    #print(score)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805c59ddd524adaba218f9cc091d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------------------------------------+------------------+------------------------------------+\n",
      "|      asin|          price|                               title|             brand|                            category|\n",
      "+----------+---------------+------------------------------------+------------------+------------------------------------+\n",
      "|B00QGMY3EU|$18.60 - $34.99|Clementine Little Girls' Girls Ta...|Clementine Apparel|['Clothing, Shoes & Jewelry', 'Gi...|\n",
      "|B006PFJMGW|         $29.99|Rare Editions Little Girls' Tutu ...|     Rare Editions|['Clothing, Shoes & Jewelry', 'Gi...|\n",
      "|B00SH78APA|$10.13 - $22.99|  Hello Kitty Baby Girls' Tutu Dress|       Hello Kitty|['Clothing, Shoes & Jewelry', 'No...|\n",
      "|B0053WLHEI|         $19.95|Rare Editions Little Girls' Tutu ...|     Rare Editions|['Clothing, Shoes & Jewelry', 'Gi...|\n",
      "|B00P835VGC|$25.99 - $28.00|Bloch Girls' Toddler Tiffany Dres...|             Bloch|['Clothing, Shoes & Jewelry', 'Gi...|\n",
      "+----------+---------------+------------------------------------+------------------+------------------------------------+"
     ]
    }
   ],
   "source": [
    "### Recomendar entonces los m con mayor score\n",
    "import numpy as np\n",
    "index_recomendados = np.argsort(scores)[::-1][:m]\n",
    "asin_rec = list(np.array(asin_son)[index_recomendados])\n",
    "\n",
    "\n",
    "### Los articulos recomendados segun el score serian entonces estos\n",
    "recomendaciones_cold_start = cruzados_sim_1.filter(col('asin').isin(asin_rec))\n",
    "recomendaciones_cold_start.show(truncate=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla anterior muestra los productos más afines al producto nuevo.\n",
    "\n",
    "Este ejemplo muestra que efectivamente el modelo logra encontrar los productos más parecidos al producto nuevo, no solo según su título, sino también mirando su precio, marca y categorías. Esto indica que el modelo está funcionando de la forma esperada y cumpliría correctamente su función de enfrentarse con el problema de cold start. Así, para alguien que haya adquirido algunos de los productos que se muestran en la tabla anterior, es buena opcion recomendarle el producto nuevo, del cual usamos solamente su metadata. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
